{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22913260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100/300,loss=0.2512\n",
      "epoch 200/300,loss=0.0073\n",
      "epoch 300/300,loss=0.0011\n",
      "final loss=0.0011\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "with open(\"Intent.json\",'r') as f:\n",
    "    intents=json.load(f)\n",
    "\n",
    "lt=WordNetLemmatizer()\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "def tokenize(sentence):\n",
    "    return word_tokenize(sentence)\n",
    "def lemm(word):\n",
    "    return lt.lemmatize(word.lower())    \n",
    "def bag_of_words(tks,all_words):\n",
    "    tks=[lemm(w) for w in tks if w not in ignore_words]\n",
    "    bag=np.zeros(len(all_words))\n",
    "    for i,word in enumerate(all_words):\n",
    "        if word in tks:\n",
    "            bag[i]=1.0\n",
    "    return bag\n",
    "\n",
    "all_words=[]\n",
    "tags=[]\n",
    "xy=[]\n",
    "ignore_words=['!','?','.',',']\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    tag=intent['tag']\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        tokenized_sent=tokenize(pattern)\n",
    "        lem_sent=[lemm(w) for w in tokenized_sent if w not in ignore_words]\n",
    "        all_words.extend(lem_sent)\n",
    "        xy.append((lem_sent,tag))\n",
    "all_words=sorted(set(all_words))\n",
    "tags=sorted(set(tags))\n",
    "\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "\n",
    "for (pattern,tag) in xy:\n",
    "        bag=bag_of_words(pattern,all_words)\n",
    "        X_train.append(bag)\n",
    "        y_train.append(tags.index(tag))\n",
    "\n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "\n",
    "class ChatDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.n_samples=len(X_train)\n",
    "        self.x_data=X_train\n",
    "        self.y_data=y_train\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_data[idx], self.y_data[idx]\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_classes):\n",
    "        super(NeuralNet,self).__init__()\n",
    "        self.l1=nn.Linear(input_size,hidden_size)\n",
    "        self.l2=nn.Linear(hidden_size,hidden_size)\n",
    "        self.l3=nn.Linear(hidden_size,num_classes)\n",
    "        self.relu=nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        out=self.l1(x)\n",
    "        out=self.relu(out)\n",
    "        out=self.l2(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.l3(out)\n",
    "        return out\n",
    "         \n",
    "        \n",
    "\n",
    "data=ChatDataset()\n",
    "train_loader=DataLoader(dataset=data,batch_size=8,shuffle=True)\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=NeuralNet(len(X_train[0]),8,len(tags)).to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "opt=torch.optim.Adam(model.parameters(),0.001)\n",
    "\n",
    "\n",
    "for epoch in range(300):\n",
    "    for (words,labels) in train_loader:\n",
    "        words=words.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(words.to(torch.float32))\n",
    "        loss=criterion(outputs,labels.type(torch.LongTensor))\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    if (epoch+1)%100==0:\n",
    "        print(f\"epoch {epoch+1}/300,loss={loss.item():.4f}\")\n",
    "print(f\"final loss={loss.item():.4f}\")\n",
    "\n",
    "d ={'model_state':model.state_dict(),\n",
    " 'input_size':X_train[0],\n",
    " 'hidden_size':8,\n",
    " 'output_size':len(tags),\n",
    " 'all_words':all_words,\n",
    "  'tags':tags}\n",
    "torch.save(d,\"data.pth\")\n",
    "\n",
    "model.load_state_dict(d['model_state'])\n",
    "model.eval()\n",
    "def get_response(sentence):\n",
    "    sentence=tokenize(sentence)\n",
    "    X=bag_of_words(sentence,all_words)\n",
    "    X=X.reshape(1,X.shape[0])\n",
    "    X=torch.from_numpy(X).to(device)\n",
    "    output=model(X.to(torch.float32))\n",
    "    _,predicted=torch.max(output,dim=1)\n",
    "    tag=tags[predicted.item()]\n",
    "    probs=torch.softmax(output,dim=1)\n",
    "    prob=probs[0][predicted.item()]\n",
    "    if prob>=0.80:\n",
    "        for intent in intents['intents']:\n",
    "            if intent['tag']==tag:\n",
    "                response=random.choice(intent['responses'])\n",
    "                return response\n",
    "    return \"I am sorry I could not understand you\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ed5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b94af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
